{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwR3Q8nIJlF6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from statistics import mean \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBJxxmTyJlGc",
    "outputId": "07eaaf7b-75e9-4f37-d47b-9a0d5ebd98b8"
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('processedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4VMXyDUJlIO"
   },
   "outputs": [],
   "source": [
    "y = d['class'] #sets y to be class column \n",
    "X = d.iloc[:,0:(d.shape[1]-1)] #sets X to be dataset with class column removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrFwIp1YJlIY",
    "outputId": "9dcc1203-b64e-40f7-f8ea-a709b062de9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X169</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>-38</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>-94</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>-80</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-59</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11495</th>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-23</td>\n",
       "      <td>-26</td>\n",
       "      <td>-36</td>\n",
       "      <td>-42</td>\n",
       "      <td>-45</td>\n",
       "      <td>-42</td>\n",
       "      <td>-45</td>\n",
       "      <td>-49</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-18</td>\n",
       "      <td>-37</td>\n",
       "      <td>-47</td>\n",
       "      <td>-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11496</th>\n",
       "      <td>-47</td>\n",
       "      <td>-11</td>\n",
       "      <td>28</td>\n",
       "      <td>77</td>\n",
       "      <td>141</td>\n",
       "      <td>211</td>\n",
       "      <td>246</td>\n",
       "      <td>240</td>\n",
       "      <td>193</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>-94</td>\n",
       "      <td>-65</td>\n",
       "      <td>-33</td>\n",
       "      <td>-7</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>77</td>\n",
       "      <td>117</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11497</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>-13</td>\n",
       "      <td>-16</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-42</td>\n",
       "      <td>-65</td>\n",
       "      <td>-48</td>\n",
       "      <td>-61</td>\n",
       "      <td>-62</td>\n",
       "      <td>-67</td>\n",
       "      <td>-30</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11498</th>\n",
       "      <td>-40</td>\n",
       "      <td>-25</td>\n",
       "      <td>-9</td>\n",
       "      <td>-12</td>\n",
       "      <td>-2</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>121</td>\n",
       "      <td>135</td>\n",
       "      <td>148</td>\n",
       "      <td>143</td>\n",
       "      <td>116</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>29</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>-94</td>\n",
       "      <td>-59</td>\n",
       "      <td>-25</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11500 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1   X2   X3   X4   X5   X6   X7   X8   X9  X10  ...  X169  X170  \\\n",
       "0      135  190  229  223  192  125   55   -9  -33  -38  ...     8   -17   \n",
       "1      386  382  356  331  320  315  307  272  244  232  ...   168   164   \n",
       "2      -32  -39  -47  -37  -32  -36  -57  -73  -85  -94  ...    29    57   \n",
       "3     -105 -101  -96  -92  -89  -95 -102 -100  -87  -79  ...   -80   -82   \n",
       "4       -9  -65  -98 -102  -78  -48  -16    0  -21  -59  ...    10     4   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "11495  -22  -22  -23  -26  -36  -42  -45  -42  -45  -49  ...    20    15   \n",
       "11496  -47  -11   28   77  141  211  246  240  193  136  ...   -94   -65   \n",
       "11497   14    6  -13  -16   10   26   27   -9    4   14  ...   -42   -65   \n",
       "11498  -40  -25   -9  -12   -2   12    7   19   22   29  ...   114   121   \n",
       "11499   29   41   57   72   74   62   54   43   31   23  ...   -94   -59   \n",
       "\n",
       "       X171  X172  X173  X174  X175  X176  X177  X178  \n",
       "0       -15   -31   -77  -103  -127  -116   -83   -51  \n",
       "1       150   146   152   157   156   154   143   129  \n",
       "2        64    48    19   -12   -30   -35   -35   -36  \n",
       "3       -81   -80   -77   -85   -77   -72   -69   -65  \n",
       "4         2   -12   -32   -41   -65   -83   -89   -73  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "11495    16    12     5    -1   -18   -37   -47   -48  \n",
       "11496   -33    -7    14    27    48    77   117   170  \n",
       "11497   -48   -61   -62   -67   -30    -2    -1    -8  \n",
       "11498   135   148   143   116    86    68    59    55  \n",
       "11499   -25    -4     2     5     4    -2     2    20  \n",
       "\n",
       "[11500 rows x 178 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double checking that X does not have the label column (leaving the labels as a feature is a common mistake): \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X) \n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "set4NSmUJlIi"
   },
   "outputs": [],
   "source": [
    "#Train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1843\n",
      "           1       0.99      0.61      0.75       457\n",
      "\n",
      "    accuracy                           0.92      2300\n",
      "   macro avg       0.95      0.80      0.85      2300\n",
      "weighted avg       0.93      0.92      0.91      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "modelKNN = KNeighborsClassifier()   \n",
    "modelKNN.fit(X_train, y_train)\n",
    "print(classification_report(y_test,modelKNN.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQtjJ5WsJlIv"
   },
   "outputs": [],
   "source": [
    "#85% might seem  pretty bad considering the fact that we only have two classes \n",
    "#and one of them makes up 80% of the dataset...\n",
    "#However, the precision and recall and f-score aren't 0, which means \n",
    "#the model is still learning at least.\n",
    "#Still, everything is rather low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I proceed to try some more simple models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      1843\n",
      "           1       0.92      0.11      0.19       457\n",
      "\n",
      "    accuracy                           0.82      2300\n",
      "   macro avg       0.87      0.55      0.55      2300\n",
      "weighted avg       0.84      0.82      0.76      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Logistic regression: \n",
    "from sklearn import linear_model\n",
    "modelLR = linear_model.LogisticRegression(C=1e5, max_iter=1000)    \n",
    "modelLR.fit(X_train, y_train)\n",
    "print(classification_report(y_test, modelLR.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1843\n",
      "           1       0.95      0.95      0.95       457\n",
      "\n",
      "    accuracy                           0.98      2300\n",
      "   macro avg       0.97      0.97      0.97      2300\n",
      "weighted avg       0.98      0.98      0.98      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Random forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF=RandomForestClassifier(n_estimators=1000)   \n",
    "modelRF.fit(X_train, y_train)\n",
    "print(classification_report(y_test, modelRF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1843\n",
      "           1       0.92      0.86      0.89       457\n",
      "\n",
      "    accuracy                           0.96      2300\n",
      "   macro avg       0.94      0.92      0.93      2300\n",
      "weighted avg       0.96      0.96      0.96      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Neural network: \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "modelNeuralNet = MLPClassifier(hidden_layer_sizes=(5,5,5), max_iter=500) \n",
    "modelNeuralNet.fit(X_train, y_train)\n",
    "print(classification_report(y_test,modelNeuralNet.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definitely room for improvement on all 4 baselines.\n",
    "#The slower ones (RF, NN) have higher performance as expected\n",
    "#I tried out some other models. SVM, adaboost, and GBMs all perform similarly to RF\n",
    "#But to keep our presentation from getting cluttered, let's just stick to these\n",
    "#4 baseline models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validations (could only do 3 fold):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_cv_results = cross_validate(modelKNN, X, y, cv=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_cv_results = cross_validate(modelLR, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNet_cv_results = cross_validate(modelNeuralNet, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_cv_results = cross_validate(modelRF, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      "KNN_cv_results: 0.921043824862773\n",
      "LR_cv_results: 0.8222610180931113\n",
      "NeuralNet_cv_results: 0.9523479463388507\n",
      "RandomForest_cv_results: 0.9736522415616372\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracies:\")\n",
    "print(\"KNN_cv_results: \" + str(mean(KNN_cv_results['test_score'])))\n",
    "print(\"LR_cv_results: \" + str(mean(LR_cv_results['test_score'])))\n",
    "print(\"NeuralNet_cv_results: \" + str(mean(NeuralNet_cv_results['test_score'])))\n",
    "print(\"RandomForest_cv_results: \" + str(mean(RF_cv_results['test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training times:\n",
      "KNN_cv_results: 0.551640510559082\n",
      "LR_cv_results: 1.9729771614074707\n",
      "NeuralNet_cv_results: 11.99180261294047\n",
      "RandomForest_cv_results: 154.31054258346558\n"
     ]
    }
   ],
   "source": [
    "print(\"Training times:\")\n",
    "print(\"KNN_cv_results: \" + str(mean(KNN_cv_results['fit_time'])))\n",
    "print(\"LR_cv_results: \" + str(mean(LR_cv_results['fit_time'])))\n",
    "print(\"NeuralNet_cv_results: \" + str(mean(NeuralNet_cv_results['fit_time'])))\n",
    "print(\"RandomForest_cv_results: \" + str(mean(RF_cv_results['fit_time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction times:\n",
      "KNN_cv_results: 15.217592239379883\n",
      "LR_cv_results: 0.0013321240743001301\n",
      "NeuralNet_cv_results: 0.00799266497294108\n",
      "RandomForest_cv_results: 1.0223230520884197\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction times:\")\n",
    "print(\"KNN_cv_results: \" + str(mean(KNN_cv_results['score_time'])))\n",
    "print(\"LR_cv_results: \" + str(mean(LR_cv_results['score_time'])))\n",
    "print(\"NeuralNet_cv_results: \" + str(mean(NeuralNet_cv_results['score_time'])))\n",
    "print(\"RandomForest_cv_results: \" + str(mean(RF_cv_results['score_time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphingY=[mean(KNN_cv_results['test_score']), \n",
    "   mean(LR_cv_results['test_score']),\n",
    "   mean(NeuralNet_cv_results['test_score']),\n",
    "   mean(RF_cv_results['test_score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xLabels=(\"SVM\",\"LogisticR\",\"NeuralNet\",\"RF\")\n",
    "x = np.arange(4)\n",
    "\n",
    "colours = ['turquoise','lightseagreen','teal',\"darkcyan\"]\n",
    "plt.bar(x, graphingY, width=0.5, color=colours)\n",
    "plt.xticks(x, xLabels, rotation=45)\n",
    "\n",
    "plt.title(\"Accuracies from CV on raw data:\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The cross validation process is also in reportingFramework.py\n",
    "#In the other notebooks, we'll just use reportingFramework.py to keep things concise\n",
    "#For reference, this is how it will be used:\n",
    "#from CVreportingFramework import hugeFramework\n",
    "#hugeFramework(modelKNN, modelLR, modelNeuralNet, modelRF, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "initialProcessingAndAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
