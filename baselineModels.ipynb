{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwR3Q8nIJlF6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from statistics import mean \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBJxxmTyJlGc",
    "outputId": "07eaaf7b-75e9-4f37-d47b-9a0d5ebd98b8"
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('processedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4VMXyDUJlIO"
   },
   "outputs": [],
   "source": [
    "y = d['class'] #sets y to be class column \n",
    "X = d.iloc[:,0:(d.shape[1]-1)] #sets X to be dataset with class column removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qrFwIp1YJlIY",
    "outputId": "9dcc1203-b64e-40f7-f8ea-a709b062de9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X169</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>-38</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>-94</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>-80</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-59</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11495</th>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-23</td>\n",
       "      <td>-26</td>\n",
       "      <td>-36</td>\n",
       "      <td>-42</td>\n",
       "      <td>-45</td>\n",
       "      <td>-42</td>\n",
       "      <td>-45</td>\n",
       "      <td>-49</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-18</td>\n",
       "      <td>-37</td>\n",
       "      <td>-47</td>\n",
       "      <td>-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11496</th>\n",
       "      <td>-47</td>\n",
       "      <td>-11</td>\n",
       "      <td>28</td>\n",
       "      <td>77</td>\n",
       "      <td>141</td>\n",
       "      <td>211</td>\n",
       "      <td>246</td>\n",
       "      <td>240</td>\n",
       "      <td>193</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>-94</td>\n",
       "      <td>-65</td>\n",
       "      <td>-33</td>\n",
       "      <td>-7</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>77</td>\n",
       "      <td>117</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11497</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>-13</td>\n",
       "      <td>-16</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-42</td>\n",
       "      <td>-65</td>\n",
       "      <td>-48</td>\n",
       "      <td>-61</td>\n",
       "      <td>-62</td>\n",
       "      <td>-67</td>\n",
       "      <td>-30</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11498</th>\n",
       "      <td>-40</td>\n",
       "      <td>-25</td>\n",
       "      <td>-9</td>\n",
       "      <td>-12</td>\n",
       "      <td>-2</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>121</td>\n",
       "      <td>135</td>\n",
       "      <td>148</td>\n",
       "      <td>143</td>\n",
       "      <td>116</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>29</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>-94</td>\n",
       "      <td>-59</td>\n",
       "      <td>-25</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11500 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1   X2   X3   X4   X5   X6   X7   X8   X9  X10  ...  X169  X170  \\\n",
       "0      135  190  229  223  192  125   55   -9  -33  -38  ...     8   -17   \n",
       "1      386  382  356  331  320  315  307  272  244  232  ...   168   164   \n",
       "2      -32  -39  -47  -37  -32  -36  -57  -73  -85  -94  ...    29    57   \n",
       "3     -105 -101  -96  -92  -89  -95 -102 -100  -87  -79  ...   -80   -82   \n",
       "4       -9  -65  -98 -102  -78  -48  -16    0  -21  -59  ...    10     4   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "11495  -22  -22  -23  -26  -36  -42  -45  -42  -45  -49  ...    20    15   \n",
       "11496  -47  -11   28   77  141  211  246  240  193  136  ...   -94   -65   \n",
       "11497   14    6  -13  -16   10   26   27   -9    4   14  ...   -42   -65   \n",
       "11498  -40  -25   -9  -12   -2   12    7   19   22   29  ...   114   121   \n",
       "11499   29   41   57   72   74   62   54   43   31   23  ...   -94   -59   \n",
       "\n",
       "       X171  X172  X173  X174  X175  X176  X177  X178  \n",
       "0       -15   -31   -77  -103  -127  -116   -83   -51  \n",
       "1       150   146   152   157   156   154   143   129  \n",
       "2        64    48    19   -12   -30   -35   -35   -36  \n",
       "3       -81   -80   -77   -85   -77   -72   -69   -65  \n",
       "4         2   -12   -32   -41   -65   -83   -89   -73  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "11495    16    12     5    -1   -18   -37   -47   -48  \n",
       "11496   -33    -7    14    27    48    77   117   170  \n",
       "11497   -48   -61   -62   -67   -30    -2    -1    -8  \n",
       "11498   135   148   143   116    86    68    59    55  \n",
       "11499   -25    -4     2     5     4    -2     2    20  \n",
       "\n",
       "[11500 rows x 178 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double checking that X does not have the label column (leaving the labels as a feature is a common mistake): \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "set4NSmUJlIi"
   },
   "outputs": [],
   "source": [
    "#Train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sW0HeTTpJlIo",
    "outputId": "efcfa6f4-9e58-44b5-fbe3-eeb5e3b6f748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.89      1828\n",
      "           1       0.00      0.00      0.00       472\n",
      "\n",
      "    accuracy                           0.79      2300\n",
      "   macro avg       0.40      0.50      0.44      2300\n",
      "weighted avg       0.63      0.79      0.70      2300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "##SVM \n",
    "from sklearn import svm\n",
    "modelSVM = svm.SVC(gamma=0.001, C=100.) \n",
    "modelSVM.fit(X_train, y_train)\n",
    "print(classification_report(y_test,modelSVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQtjJ5WsJlIv"
   },
   "outputs": [],
   "source": [
    "#80% might seem  pretty bad considering the fact that we only have two classes \n",
    "#and one of them makes up 80% of the dataset...\n",
    "#However, the precision and recall and f-score aren't 0, which means \n",
    "#the model is still learning at least.\n",
    "#Still, everything is quite low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I proceed to try some more simple non-deep learning models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90      1828\n",
      "           1       0.95      0.11      0.20       472\n",
      "\n",
      "    accuracy                           0.82      2300\n",
      "   macro avg       0.88      0.56      0.55      2300\n",
      "weighted avg       0.84      0.82      0.75      2300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "##Logistic regression: \n",
    "from sklearn import linear_model\n",
    "modelLR = linear_model.LogisticRegression(C=1e5, max_iter=1000)    \n",
    "modelLR.fit(X_train, y_train)\n",
    "print(classification_report(y_test, modelLR.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1828\n",
      "           1       0.95      0.93      0.94       472\n",
      "\n",
      "    accuracy                           0.97      2300\n",
      "   macro avg       0.96      0.96      0.96      2300\n",
      "weighted avg       0.97      0.97      0.97      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Random forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF=RandomForestClassifier(n_estimators=1000)   \n",
    "modelRF.fit(X_train, y_train)\n",
    "print(classification_report(y_test, modelRF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural network: \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1828\n",
      "           1       0.91      0.88      0.89       472\n",
      "\n",
      "    accuracy                           0.96      2300\n",
      "   macro avg       0.94      0.93      0.93      2300\n",
      "weighted avg       0.96      0.96      0.96      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelNeuralNet = MLPClassifier(hidden_layer_sizes=(5,5,5), max_iter=500) \n",
    "#3 hidden layers with 13 neurons in each layer \n",
    "modelNeuralNet.fit(X_train, y_train)\n",
    "print(classification_report(y_test,modelNeuralNet.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definitely room for improvement on all 4 baselines.\n",
    "#The slower ones (RF, NN) have higher performance as expected\n",
    "#I tried out some other models. kNN performs similarly to SVM and logistic regression, \n",
    "#and adaboost and GBMs perform similarly to the random forest. \n",
    "#But to keep our presentation from getting cluttered, let's just stick to these\n",
    "#4 baseline models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validations (could only do 3 fold):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_cv_results = cross_validate(modelSVM, X, y, cv=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "LR_cv_results = cross_validate(modelLR, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNet_cv_results = cross_validate(modelNeuralNet, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_cv_results = cross_validate(modelRF, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      "SVM_cv_results: 0.8000000045364676\n",
      "LR_cv_results: 0.8223479368122687\n",
      "NeuralNet_cv_results: 0.9439992355144806\n",
      "RandomForest_cv_results: 0.974521768988281\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracies:\")\n",
    "print(\"SVM_cv_results: \" + str(mean(SVM_cv_results['test_score'])))\n",
    "print(\"LR_cv_results: \" + str(mean(LR_cv_results['test_score'])))\n",
    "print(\"NeuralNet_cv_results: \" + str(mean(NeuralNet_cv_results['test_score'])))\n",
    "print(\"RandomForest_cv_results: \" + str(mean(RF_cv_results['test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training times:\n",
      "SVM_cv_results: 63.57625985145569\n",
      "LR_cv_results: 3.0736148357391357\n",
      "NeuralNet_cv_results: 10.491767009099325\n",
      "RandomForest_cv_results: 148.41069642702737\n"
     ]
    }
   ],
   "source": [
    "print(\"Training times:\")\n",
    "print(\"SVM_cv_results: \" + str(mean(SVM_cv_results['fit_time'])))\n",
    "print(\"LR_cv_results: \" + str(mean(LR_cv_results['fit_time'])))\n",
    "print(\"NeuralNet_cv_results: \" + str(mean(NeuralNet_cv_results['fit_time'])))\n",
    "print(\"RandomForest_cv_results: \" + str(mean(RF_cv_results['fit_time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction times:\n",
      "SVM_cv_results: 8.91124709447225\n",
      "LR_cv_results: 0.005208015441894531\n",
      "NeuralNet_cv_results: 0.010067224502563477\n",
      "RandomForest_cv_results: 1.3545056978861492\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction times:\")\n",
    "print(\"SVM_cv_results: \" + str(mean(SVM_cv_results['score_time'])))\n",
    "print(\"LR_cv_results: \" + str(mean(LR_cv_results['score_time'])))\n",
    "print(\"NeuralNet_cv_results: \" + str(mean(NeuralNet_cv_results['score_time'])))\n",
    "print(\"RandomForest_cv_results: \" + str(mean(RF_cv_results['score_time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphingY=[mean(SVM_cv_results['test_score']), \n",
    "   mean(LR_cv_results['test_score']),\n",
    "   mean(NeuralNet_cv_results['test_score']),\n",
    "   mean(RF_cv_results['test_score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xLabels=(\"SVM\",\"LogisticR\",\"NeuralNet\",\"RF\")\n",
    "x = np.arange(4)\n",
    "\n",
    "colours = ['turquoise','lightseagreen','teal',\"darkcyan\"]\n",
    "plt.bar(x, graphingY, width=0.5, color=colours)\n",
    "plt.xticks(x, xLabels, rotation=45)\n",
    "\n",
    "plt.title(\"Accuracies from CV on raw data:\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      "SVM_cv_results: 0.8000000045364676\n",
      "LR_cv_results: 0.8223479368122687\n",
      "NeuralNet_cv_results: 0.9288695036555537\n",
      "RandomForest_cv_results: 0.9735652774778039\n",
      "\n",
      "Training times:\n",
      "SVM_cv_results: 68.79273184140523\n",
      "LR_cv_results: 3.713141600290934\n",
      "NeuralNet_cv_results: 14.130476156870523\n",
      "RandomForest_cv_results: 149.98129645983377\n",
      "\n",
      "Prediction times:\n",
      "SVM_cv_results: 9.958036184310913\n",
      "LR_cv_results: 0.010134458541870117\n",
      "NeuralNet_cv_results: 0.01755682627360026\n",
      "RandomForest_cv_results: 1.3544005552927654\n"
     ]
    }
   ],
   "source": [
    "#The cross validation stuff is in reportingFramework.py\n",
    "#In the other notebooks, we'll just use this method to keep things concise\n",
    "\n",
    "from CVreportingFramework import hugeFramework\n",
    "hugeFramework(modelSVM, modelLR, modelNeuralNet, modelRF, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "initialProcessingAndAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
