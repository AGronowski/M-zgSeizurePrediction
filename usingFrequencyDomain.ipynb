{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statistics import mean \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>-38</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>-94</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-59</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2   X3   X4   X5   X6   X7   X8   X9  X10  ...  X170  X171  X172  \\\n",
       "0  135  190  229  223  192  125   55   -9  -33  -38  ...   -17   -15   -31   \n",
       "1  386  382  356  331  320  315  307  272  244  232  ...   164   150   146   \n",
       "2  -32  -39  -47  -37  -32  -36  -57  -73  -85  -94  ...    57    64    48   \n",
       "3 -105 -101  -96  -92  -89  -95 -102 -100  -87  -79  ...   -82   -81   -80   \n",
       "4   -9  -65  -98 -102  -78  -48  -16    0  -21  -59  ...     4     2   -12   \n",
       "\n",
       "   X173  X174  X175  X176  X177  X178  class  \n",
       "0   -77  -103  -127  -116   -83   -51      0  \n",
       "1   152   157   156   154   143   129      1  \n",
       "2    19   -12   -30   -35   -35   -36      0  \n",
       "3   -77   -85   -77   -72   -69   -65      0  \n",
       "4   -32   -41   -65   -83   -89   -73      0  \n",
       "\n",
       "[5 rows x 179 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('processedData.csv')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 135,  190,  229,  223,  192,  125,   55,   -9,  -33,  -38,  -10,\n",
       "         35,   64,  113,  152,  164,  127,   50,  -47, -121, -138, -125,\n",
       "       -101,  -50,   11,   39,   24,   48,   64,   46], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = d.iloc[:,:178].values #the indexing includes every column except class \n",
    "X[0,0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = d.iloc[:,178].values\n",
    "y[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fft = np.fft.fft(X,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11500, 178)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\numpy\\core\\_asarray.py:85: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x258d9c39288>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_fft = X_fft[:,0:30]\n",
    "plt.subplot(511)\n",
    "plt.plot(X_fft[1,:])\n",
    "plt.subplot(512)\n",
    "plt.plot(X_fft[7,:])\n",
    "plt.subplot(513)\n",
    "plt.plot(X_fft[12,:])\n",
    "plt.subplot(514)\n",
    "plt.plot(X_fft[0,:])\n",
    "plt.subplot(515)\n",
    "plt.plot(X_fft[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fft, X_test_fft, y_train_fft, y_test_fft = train_test_split(X_fft, y, test_size = 0.2)\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dft(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    N = x.shape[0]\n",
    "    n = np.arange(N)\n",
    "    k = n.reshape((N, 1))\n",
    "    M = np.exp(-2j * np.pi * k * n / N)\n",
    "    return np.dot(M, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-95b5c27e40a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-f3ee19000a1c>\u001b[0m in \u001b[0;36mdft\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2j\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dft(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Complex data not supported\n[[ -3010.            +0.j           2446.79079212  +450.26036407j\n   -2657.82926858 -1481.14375235j ...   3723.26645434 +2659.48430797j\n   -2657.82926858 +1481.14375235j   2446.79079212  -450.26036407j]\n [  5004.            +0.j           1307.72458087 -7404.53273831j\n   15020.76766779 +7130.18903044j ... -25344.16111885-18210.88127508j\n   15020.76766779 -7130.18903044j   1307.72458087 +7404.53273831j]\n [ -7840.            +0.j            936.49675216  -664.89349595j\n     440.28950635 +2359.5200808j  ...   -347.45932081 -1292.8126898j\n     440.28950635 -2359.5200808j     936.49675216  +664.89349595j]\n ...\n [  1202.            +0.j          -1370.81722374 -1786.42314571j\n    -406.88133027 -3340.19316663j ...    -40.29865635  +127.31387513j\n    -406.88133027 +3340.19316663j  -1370.81722374 +1786.42314571j]\n [ -6914.            +0.j           1291.36233245  +218.99684588j\n    2986.66355234 +1355.36334052j ...   4678.64222263 -1123.29490953j\n    2986.66355234 -1355.36334052j   1291.36233245  -218.99684588j]\n [  -376.            +0.j            389.45911217  +655.31067299j\n    1873.59850321 -2247.98216097j ...   -520.23628273  -554.33190571j\n    1873.59850321 +2247.98216097j    389.45911217  -655.31067299j]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComplexWarning\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mComplexWarning\u001b[0m: Casting complex values to real discards the imaginary part",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-6ee22ba587b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbruv\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    698\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[0;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n\u001b[1;32m--> 518\u001b[1;33m                                  \"{}\\n\".format(array))\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;31m# It is possible that the np.array(..) gave no warning. This happens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Complex data not supported\n[[ -3010.            +0.j           2446.79079212  +450.26036407j\n   -2657.82926858 -1481.14375235j ...   3723.26645434 +2659.48430797j\n   -2657.82926858 +1481.14375235j   2446.79079212  -450.26036407j]\n [  5004.            +0.j           1307.72458087 -7404.53273831j\n   15020.76766779 +7130.18903044j ... -25344.16111885-18210.88127508j\n   15020.76766779 -7130.18903044j   1307.72458087 +7404.53273831j]\n [ -7840.            +0.j            936.49675216  -664.89349595j\n     440.28950635 +2359.5200808j  ...   -347.45932081 -1292.8126898j\n     440.28950635 -2359.5200808j     936.49675216  +664.89349595j]\n ...\n [  1202.            +0.j          -1370.81722374 -1786.42314571j\n    -406.88133027 -3340.19316663j ...    -40.29865635  +127.31387513j\n    -406.88133027 +3340.19316663j  -1370.81722374 +1786.42314571j]\n [ -6914.            +0.j           1291.36233245  +218.99684588j\n    2986.66355234 +1355.36334052j ...   4678.64222263 -1123.29490953j\n    2986.66355234 -1355.36334052j   1291.36233245  -218.99684588j]\n [  -376.            +0.j            389.45911217  +655.31067299j\n    1873.59850321 -2247.98216097j ...   -520.23628273  -554.33190571j\n    1873.59850321 +2247.98216097j    389.45911217  -655.31067299j]]\n"
     ]
    }
   ],
   "source": [
    "bruv =  sc.fit_transform(X_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Complex data not supported\n[[-2859.        +0.00000000e+00j -6434.81607014+4.62812230e+02j\n   2363.5748082 -1.41417087e+00j ...   983.51353705-8.87607273e+02j\n    477.88804929+1.30327333e+02j  -916.82727975-1.52913369e+03j]\n [ 9943.        +0.00000000e+00j   740.78911201+1.65160419e+03j\n   3212.10623935+1.94693166e+03j ...    29.16761919+3.20831407e+02j\n   -301.0947446 +1.83757231e+02j   -68.33761584+3.05916622e+02j]\n [ 2736.        +0.00000000e+00j  1134.09903042+9.25481230e+02j\n    878.62194119+1.04973532e+03j ...  -150.48170752+1.18875578e+00j\n    -26.78685081+1.04801407e+02j  -143.3337056 +1.65983002e+02j]\n ...\n [ 1815.        +0.00000000e+00j   440.63015092-3.93036073e+03j\n    585.66871058-7.40237133e+02j ...   -83.98105125-2.01777791e+02j\n    363.23610676+1.00028827e+01j    38.99594518-2.67763299e+02j]\n [ 4546.        +0.00000000e+00j   167.92283268-1.25097143e+03j\n   -969.64662452-1.23149686e+03j ...   -61.7784939 +1.49578792e+01j\n    -43.76983693+2.74759980e+01j    33.09618136+3.19941491e+01j]\n [ 1545.        +0.00000000e+00j -8014.78773871-6.73155303e+03j\n  -9078.98655393-2.97302438e+03j ...  -720.08177027-2.03658769e+03j\n    875.08045201+2.69563244e+02j   718.39385348-1.00582290e+02j]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComplexWarning\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mComplexWarning\u001b[0m: Casting complex values to real discards the imaginary part",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-13580226494d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_fft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_fft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_fft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_fft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    698\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[0;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n\u001b[1;32m--> 518\u001b[1;33m                                  \"{}\\n\".format(array))\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;31m# It is possible that the np.array(..) gave no warning. This happens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Complex data not supported\n[[-2859.        +0.00000000e+00j -6434.81607014+4.62812230e+02j\n   2363.5748082 -1.41417087e+00j ...   983.51353705-8.87607273e+02j\n    477.88804929+1.30327333e+02j  -916.82727975-1.52913369e+03j]\n [ 9943.        +0.00000000e+00j   740.78911201+1.65160419e+03j\n   3212.10623935+1.94693166e+03j ...    29.16761919+3.20831407e+02j\n   -301.0947446 +1.83757231e+02j   -68.33761584+3.05916622e+02j]\n [ 2736.        +0.00000000e+00j  1134.09903042+9.25481230e+02j\n    878.62194119+1.04973532e+03j ...  -150.48170752+1.18875578e+00j\n    -26.78685081+1.04801407e+02j  -143.3337056 +1.65983002e+02j]\n ...\n [ 1815.        +0.00000000e+00j   440.63015092-3.93036073e+03j\n    585.66871058-7.40237133e+02j ...   -83.98105125-2.01777791e+02j\n    363.23610676+1.00028827e+01j    38.99594518-2.67763299e+02j]\n [ 4546.        +0.00000000e+00j   167.92283268-1.25097143e+03j\n   -969.64662452-1.23149686e+03j ...   -61.7784939 +1.49578792e+01j\n    -43.76983693+2.74759980e+01j    33.09618136+3.19941491e+01j]\n [ 1545.        +0.00000000e+00j -8014.78773871-6.73155303e+03j\n  -9078.98655393-2.97302438e+03j ...  -720.08177027-2.03658769e+03j\n    875.08045201+2.69563244e+02j   718.39385348-1.00582290e+02j]]\n"
     ]
    }
   ],
   "source": [
    "X_train_fft = sc.fit_transform(X_train_fft)\n",
    "X_test_fft = sc.transform(X_test_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "fftX = pd.DataFrame(np.fft.rfft(X,axis=1)) #cast to dataframe so I can conconcatenate later on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING: MAKING X AND Y SMALLER FOR NOW \n",
    "#We'll want to use the full dataset when reporting final numbers\n",
    "#I'd be nice if we could do 5 fold CV, but that will take a very very long time if we're using the full dataset\n",
    "\n",
    "X = X.iloc[0:2000,:]\n",
    "fftX = fftX.iloc[0:2000,:]\n",
    "y = y.iloc[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 178)\n",
      "(2000, 90)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(fftX.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only frequency domain: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fftX, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 90)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm that only fftX is being used: there should be 90 columns: \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Complex data not supported\n                         0                          1   \\\n604  -8788.000000+0.000000j  5708.328329+10134.672561j   \n1568 -9395.000000+0.000000j   2334.869603-1870.300580j   \n480  -1156.000000+0.000000j    -504.991841+635.717354j   \n108   5865.000000+0.000000j  -6696.191849+6034.735151j   \n1043 -2875.000000+0.000000j   1430.796942-1006.132391j   \n...                     ...                        ...   \n930  -4671.000000+0.000000j   1254.695202-3708.271958j   \n46     855.000000+0.000000j    678.669892+1956.327346j   \n790  -5963.000000+0.000000j   -777.201745-1412.382335j   \n953   -892.000000+0.000000j     -269.207770+79.801160j   \n1072 -5837.000000+0.000000j    1394.538256+377.835486j   \n\n                            2                         3   \\\n604    2780.998370-314.501393j    -95.232404+974.907993j   \n1568   -395.257176-264.087456j    414.587609-396.763690j   \n480     184.449789+274.084637j  -469.358628+1785.635773j   \n108   4531.612275-7520.019901j -4080.701690-2898.602235j   \n1043  1015.351945-1482.910749j   -956.714034+378.087838j   \n...                        ...                       ...   \n930   -623.302006+1391.651449j     197.895388-79.756171j   \n46       13.561687-947.363405j   102.068237+1962.630588j   \n790    1226.853222-426.193825j   282.866656+3036.304591j   \n953   1414.301915-2535.269245j   578.927892-2683.123205j   \n1072    353.443066-445.711642j  -1592.789235-358.178666j   \n\n                            4                         5   \\\n604      -7.042932+428.575440j   1254.951227+967.647334j   \n1568     12.130984-292.276493j   1025.598694+740.955580j   \n480    -693.422669-809.701889j      86.445401+23.851638j   \n108  -2738.800868+2308.000154j  1443.230794-1032.970257j   \n1043  -248.368572-1807.166688j   473.861995-2616.534473j   \n...                        ...                       ...   \n930    269.440401-1094.541730j   -744.407385+177.529815j   \n46     -203.930122+150.435210j     658.196087+74.566679j   \n790  -4232.151600-2907.095646j  2744.391406+1380.490455j   \n953       594.816322+3.889325j  -1544.372681-172.920940j   \n1072   -455.893628-106.655407j   -966.455463-515.638628j   \n\n                           6                         7   \\\n604   -488.226042+259.083355j  1686.127980+1128.533854j   \n1568  -213.630160-171.334438j     1071.887885+4.065549j   \n480    277.969932-481.030995j   1052.821576+830.274887j   \n108  -263.459838-1571.638580j  -1158.145412+423.828856j   \n1043  709.911349-1669.181974j  -1161.120710+927.196686j   \n...                       ...                       ...   \n930    372.739896-499.815997j   1232.693521+220.169388j   \n46      71.827800-446.975428j   -764.468767+731.842634j   \n790   -131.195514-239.446678j    462.439438-999.345115j   \n953  -816.578516-1002.042296j  -1159.101694+242.366210j   \n1072   622.719570+340.621540j   -162.795155-943.489233j   \n\n                           8                        9   ...  \\\n604    784.057706+832.972955j   758.464779+303.061506j  ...   \n1568    122.956167+11.879631j  -197.115015-838.351261j  ...   \n480   858.871642+1322.690163j   766.846242+662.284864j  ...   \n108    -759.383942-26.361564j  -275.597712+918.851702j  ...   \n1043   236.824491-421.034211j  -366.919321-283.223812j  ...   \n...                       ...                      ...  ...   \n930   -1228.875175+56.022216j  -384.132343-424.631991j  ...   \n46     328.136282-929.558758j  -850.672242-665.367028j  ...   \n790   -60.741766-2451.677349j  536.281270+1333.531140j  ...   \n953  -422.072584-1815.271972j  -780.778204+466.777288j  ...   \n1072   -443.244142-19.693921j   187.789151+246.762124j  ...   \n\n                         80                      81                     82  \\\n604  -307.329255+50.109211j  -271.715524+73.322641j -285.592659+67.176458j   \n1568  -28.812135-24.499594j      8.833257+4.592628j   35.002237+12.656265j   \n480      6.798574+3.718442j    -7.580777+20.445611j   20.414104+10.904294j   \n108    25.374707-39.610004j    45.850375-10.426479j   28.789228-11.162034j   \n1043   17.095521+31.561462j  120.693796+128.447383j  38.284763-125.338522j   \n...                     ...                     ...                    ...   \n930    21.589043-15.436503j    52.086822+10.899734j   56.865256-18.388537j   \n46       3.511912-5.773200j   -21.302762-32.550169j   -45.595889-9.864502j   \n790    13.104367+18.257214j   -28.838710-23.160326j  -65.457755+86.191976j   \n953     78.298689+0.394558j    53.614551-34.330913j   60.227138-16.135897j   \n1072   -15.806639+8.149046j    43.574149+16.609876j    19.162287-7.058266j   \n\n                         83                     84                     85  \\\n604  -267.696435+53.696272j -285.193465+54.175212j -262.606740+47.992359j   \n1568    29.024643-5.525798j    -5.419846+0.586436j    1.743553-13.047884j   \n480    20.364895-26.337695j    -7.459384+0.943095j    24.210562-6.141698j   \n108     5.435982+45.768741j    29.491870-9.761595j   20.338212+18.961825j   \n1043  24.344030+133.216239j -157.397915+94.220606j   18.373604-66.492929j   \n...                     ...                    ...                    ...   \n930     51.825282-7.122598j   33.644640-25.796774j    41.393603-8.701162j   \n46     -19.753849-1.322027j  -19.659597-17.395378j    0.894073-12.853528j   \n790    -3.383257-26.886866j  -93.887003+34.040693j  -81.888564+60.106864j   \n953    90.848273-11.180504j    93.075411+1.865543j    63.863041-7.824432j   \n1072    35.581632+4.704350j   50.571061+35.995138j  -16.054746-12.762860j   \n\n                         86                    87                    88  \\\n604  -261.403229+34.129059j -257.378401+7.666345j -252.139731-2.213865j   \n1568   21.090029-22.364289j   11.964410-2.027536j   23.433118-6.635780j   \n480     22.170692+5.386839j   14.863870-5.242623j    4.592552+4.699494j   \n108    30.940568+23.769582j  32.053833+15.927478j   22.940768+4.697138j   \n1043   -27.723875-6.837443j  75.267507+40.259580j -52.278376-95.242595j   \n...                     ...                   ...                   ...   \n930    18.237049-17.813142j   51.849250+1.342216j   37.319872-6.076890j   \n46     -5.588398-22.540657j -15.681470-13.158548j   6.190644-27.341979j   \n790   -48.287558+55.305519j  32.742069+13.978292j -86.759819-77.007765j   \n953    72.136636-20.084143j   77.668720-8.815140j  98.704081-31.788379j   \n1072    3.979175+39.488064j   45.356455-2.883872j  29.376515+12.244953j   \n\n                        89  \n604  -230.000000+0.000000j  \n1568    9.000000+0.000000j  \n480    26.000000+0.000000j  \n108    51.000000+0.000000j  \n1043  -13.000000+0.000000j  \n...                    ...  \n930    37.000000+0.000000j  \n46     21.000000+0.000000j  \n790    -3.000000+0.000000j  \n953    92.000000+0.000000j  \n1072  -21.000000+0.000000j  \n\n[1600 rows x 90 columns]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComplexWarning\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mComplexWarning\u001b[0m: Casting complex values to real discards the imaginary part",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-be6c54a4e428>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    698\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[0;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n\u001b[1;32m--> 518\u001b[1;33m                                  \"{}\\n\".format(array))\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;31m# It is possible that the np.array(..) gave no warning. This happens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Complex data not supported\n                         0                          1   \\\n604  -8788.000000+0.000000j  5708.328329+10134.672561j   \n1568 -9395.000000+0.000000j   2334.869603-1870.300580j   \n480  -1156.000000+0.000000j    -504.991841+635.717354j   \n108   5865.000000+0.000000j  -6696.191849+6034.735151j   \n1043 -2875.000000+0.000000j   1430.796942-1006.132391j   \n...                     ...                        ...   \n930  -4671.000000+0.000000j   1254.695202-3708.271958j   \n46     855.000000+0.000000j    678.669892+1956.327346j   \n790  -5963.000000+0.000000j   -777.201745-1412.382335j   \n953   -892.000000+0.000000j     -269.207770+79.801160j   \n1072 -5837.000000+0.000000j    1394.538256+377.835486j   \n\n                            2                         3   \\\n604    2780.998370-314.501393j    -95.232404+974.907993j   \n1568   -395.257176-264.087456j    414.587609-396.763690j   \n480     184.449789+274.084637j  -469.358628+1785.635773j   \n108   4531.612275-7520.019901j -4080.701690-2898.602235j   \n1043  1015.351945-1482.910749j   -956.714034+378.087838j   \n...                        ...                       ...   \n930   -623.302006+1391.651449j     197.895388-79.756171j   \n46       13.561687-947.363405j   102.068237+1962.630588j   \n790    1226.853222-426.193825j   282.866656+3036.304591j   \n953   1414.301915-2535.269245j   578.927892-2683.123205j   \n1072    353.443066-445.711642j  -1592.789235-358.178666j   \n\n                            4                         5   \\\n604      -7.042932+428.575440j   1254.951227+967.647334j   \n1568     12.130984-292.276493j   1025.598694+740.955580j   \n480    -693.422669-809.701889j      86.445401+23.851638j   \n108  -2738.800868+2308.000154j  1443.230794-1032.970257j   \n1043  -248.368572-1807.166688j   473.861995-2616.534473j   \n...                        ...                       ...   \n930    269.440401-1094.541730j   -744.407385+177.529815j   \n46     -203.930122+150.435210j     658.196087+74.566679j   \n790  -4232.151600-2907.095646j  2744.391406+1380.490455j   \n953       594.816322+3.889325j  -1544.372681-172.920940j   \n1072   -455.893628-106.655407j   -966.455463-515.638628j   \n\n                           6                         7   \\\n604   -488.226042+259.083355j  1686.127980+1128.533854j   \n1568  -213.630160-171.334438j     1071.887885+4.065549j   \n480    277.969932-481.030995j   1052.821576+830.274887j   \n108  -263.459838-1571.638580j  -1158.145412+423.828856j   \n1043  709.911349-1669.181974j  -1161.120710+927.196686j   \n...                       ...                       ...   \n930    372.739896-499.815997j   1232.693521+220.169388j   \n46      71.827800-446.975428j   -764.468767+731.842634j   \n790   -131.195514-239.446678j    462.439438-999.345115j   \n953  -816.578516-1002.042296j  -1159.101694+242.366210j   \n1072   622.719570+340.621540j   -162.795155-943.489233j   \n\n                           8                        9   ...  \\\n604    784.057706+832.972955j   758.464779+303.061506j  ...   \n1568    122.956167+11.879631j  -197.115015-838.351261j  ...   \n480   858.871642+1322.690163j   766.846242+662.284864j  ...   \n108    -759.383942-26.361564j  -275.597712+918.851702j  ...   \n1043   236.824491-421.034211j  -366.919321-283.223812j  ...   \n...                       ...                      ...  ...   \n930   -1228.875175+56.022216j  -384.132343-424.631991j  ...   \n46     328.136282-929.558758j  -850.672242-665.367028j  ...   \n790   -60.741766-2451.677349j  536.281270+1333.531140j  ...   \n953  -422.072584-1815.271972j  -780.778204+466.777288j  ...   \n1072   -443.244142-19.693921j   187.789151+246.762124j  ...   \n\n                         80                      81                     82  \\\n604  -307.329255+50.109211j  -271.715524+73.322641j -285.592659+67.176458j   \n1568  -28.812135-24.499594j      8.833257+4.592628j   35.002237+12.656265j   \n480      6.798574+3.718442j    -7.580777+20.445611j   20.414104+10.904294j   \n108    25.374707-39.610004j    45.850375-10.426479j   28.789228-11.162034j   \n1043   17.095521+31.561462j  120.693796+128.447383j  38.284763-125.338522j   \n...                     ...                     ...                    ...   \n930    21.589043-15.436503j    52.086822+10.899734j   56.865256-18.388537j   \n46       3.511912-5.773200j   -21.302762-32.550169j   -45.595889-9.864502j   \n790    13.104367+18.257214j   -28.838710-23.160326j  -65.457755+86.191976j   \n953     78.298689+0.394558j    53.614551-34.330913j   60.227138-16.135897j   \n1072   -15.806639+8.149046j    43.574149+16.609876j    19.162287-7.058266j   \n\n                         83                     84                     85  \\\n604  -267.696435+53.696272j -285.193465+54.175212j -262.606740+47.992359j   \n1568    29.024643-5.525798j    -5.419846+0.586436j    1.743553-13.047884j   \n480    20.364895-26.337695j    -7.459384+0.943095j    24.210562-6.141698j   \n108     5.435982+45.768741j    29.491870-9.761595j   20.338212+18.961825j   \n1043  24.344030+133.216239j -157.397915+94.220606j   18.373604-66.492929j   \n...                     ...                    ...                    ...   \n930     51.825282-7.122598j   33.644640-25.796774j    41.393603-8.701162j   \n46     -19.753849-1.322027j  -19.659597-17.395378j    0.894073-12.853528j   \n790    -3.383257-26.886866j  -93.887003+34.040693j  -81.888564+60.106864j   \n953    90.848273-11.180504j    93.075411+1.865543j    63.863041-7.824432j   \n1072    35.581632+4.704350j   50.571061+35.995138j  -16.054746-12.762860j   \n\n                         86                    87                    88  \\\n604  -261.403229+34.129059j -257.378401+7.666345j -252.139731-2.213865j   \n1568   21.090029-22.364289j   11.964410-2.027536j   23.433118-6.635780j   \n480     22.170692+5.386839j   14.863870-5.242623j    4.592552+4.699494j   \n108    30.940568+23.769582j  32.053833+15.927478j   22.940768+4.697138j   \n1043   -27.723875-6.837443j  75.267507+40.259580j -52.278376-95.242595j   \n...                     ...                   ...                   ...   \n930    18.237049-17.813142j   51.849250+1.342216j   37.319872-6.076890j   \n46     -5.588398-22.540657j -15.681470-13.158548j   6.190644-27.341979j   \n790   -48.287558+55.305519j  32.742069+13.978292j -86.759819-77.007765j   \n953    72.136636-20.084143j   77.668720-8.815140j  98.704081-31.788379j   \n1072    3.979175+39.488064j   45.356455-2.883872j  29.376515+12.244953j   \n\n                        89  \n604  -230.000000+0.000000j  \n1568    9.000000+0.000000j  \n480    26.000000+0.000000j  \n108    51.000000+0.000000j  \n1043  -13.000000+0.000000j  \n...                    ...  \n930    37.000000+0.000000j  \n46     21.000000+0.000000j  \n790    -3.000000+0.000000j  \n953    92.000000+0.000000j  \n1072  -21.000000+0.000000j  \n\n[1600 rows x 90 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Complex data not supported\n                         0                          1   \\\n604  -8788.000000+0.000000j  5708.328329+10134.672561j   \n1568 -9395.000000+0.000000j   2334.869603-1870.300580j   \n480  -1156.000000+0.000000j    -504.991841+635.717354j   \n108   5865.000000+0.000000j  -6696.191849+6034.735151j   \n1043 -2875.000000+0.000000j   1430.796942-1006.132391j   \n...                     ...                        ...   \n930  -4671.000000+0.000000j   1254.695202-3708.271958j   \n46     855.000000+0.000000j    678.669892+1956.327346j   \n790  -5963.000000+0.000000j   -777.201745-1412.382335j   \n953   -892.000000+0.000000j     -269.207770+79.801160j   \n1072 -5837.000000+0.000000j    1394.538256+377.835486j   \n\n                            2                         3   \\\n604    2780.998370-314.501393j    -95.232404+974.907993j   \n1568   -395.257176-264.087456j    414.587609-396.763690j   \n480     184.449789+274.084637j  -469.358628+1785.635773j   \n108   4531.612275-7520.019901j -4080.701690-2898.602235j   \n1043  1015.351945-1482.910749j   -956.714034+378.087838j   \n...                        ...                       ...   \n930   -623.302006+1391.651449j     197.895388-79.756171j   \n46       13.561687-947.363405j   102.068237+1962.630588j   \n790    1226.853222-426.193825j   282.866656+3036.304591j   \n953   1414.301915-2535.269245j   578.927892-2683.123205j   \n1072    353.443066-445.711642j  -1592.789235-358.178666j   \n\n                            4                         5   \\\n604      -7.042932+428.575440j   1254.951227+967.647334j   \n1568     12.130984-292.276493j   1025.598694+740.955580j   \n480    -693.422669-809.701889j      86.445401+23.851638j   \n108  -2738.800868+2308.000154j  1443.230794-1032.970257j   \n1043  -248.368572-1807.166688j   473.861995-2616.534473j   \n...                        ...                       ...   \n930    269.440401-1094.541730j   -744.407385+177.529815j   \n46     -203.930122+150.435210j     658.196087+74.566679j   \n790  -4232.151600-2907.095646j  2744.391406+1380.490455j   \n953       594.816322+3.889325j  -1544.372681-172.920940j   \n1072   -455.893628-106.655407j   -966.455463-515.638628j   \n\n                           6                         7   \\\n604   -488.226042+259.083355j  1686.127980+1128.533854j   \n1568  -213.630160-171.334438j     1071.887885+4.065549j   \n480    277.969932-481.030995j   1052.821576+830.274887j   \n108  -263.459838-1571.638580j  -1158.145412+423.828856j   \n1043  709.911349-1669.181974j  -1161.120710+927.196686j   \n...                       ...                       ...   \n930    372.739896-499.815997j   1232.693521+220.169388j   \n46      71.827800-446.975428j   -764.468767+731.842634j   \n790   -131.195514-239.446678j    462.439438-999.345115j   \n953  -816.578516-1002.042296j  -1159.101694+242.366210j   \n1072   622.719570+340.621540j   -162.795155-943.489233j   \n\n                           8                        9   ...  \\\n604    784.057706+832.972955j   758.464779+303.061506j  ...   \n1568    122.956167+11.879631j  -197.115015-838.351261j  ...   \n480   858.871642+1322.690163j   766.846242+662.284864j  ...   \n108    -759.383942-26.361564j  -275.597712+918.851702j  ...   \n1043   236.824491-421.034211j  -366.919321-283.223812j  ...   \n...                       ...                      ...  ...   \n930   -1228.875175+56.022216j  -384.132343-424.631991j  ...   \n46     328.136282-929.558758j  -850.672242-665.367028j  ...   \n790   -60.741766-2451.677349j  536.281270+1333.531140j  ...   \n953  -422.072584-1815.271972j  -780.778204+466.777288j  ...   \n1072   -443.244142-19.693921j   187.789151+246.762124j  ...   \n\n                         80                      81                     82  \\\n604  -307.329255+50.109211j  -271.715524+73.322641j -285.592659+67.176458j   \n1568  -28.812135-24.499594j      8.833257+4.592628j   35.002237+12.656265j   \n480      6.798574+3.718442j    -7.580777+20.445611j   20.414104+10.904294j   \n108    25.374707-39.610004j    45.850375-10.426479j   28.789228-11.162034j   \n1043   17.095521+31.561462j  120.693796+128.447383j  38.284763-125.338522j   \n...                     ...                     ...                    ...   \n930    21.589043-15.436503j    52.086822+10.899734j   56.865256-18.388537j   \n46       3.511912-5.773200j   -21.302762-32.550169j   -45.595889-9.864502j   \n790    13.104367+18.257214j   -28.838710-23.160326j  -65.457755+86.191976j   \n953     78.298689+0.394558j    53.614551-34.330913j   60.227138-16.135897j   \n1072   -15.806639+8.149046j    43.574149+16.609876j    19.162287-7.058266j   \n\n                         83                     84                     85  \\\n604  -267.696435+53.696272j -285.193465+54.175212j -262.606740+47.992359j   \n1568    29.024643-5.525798j    -5.419846+0.586436j    1.743553-13.047884j   \n480    20.364895-26.337695j    -7.459384+0.943095j    24.210562-6.141698j   \n108     5.435982+45.768741j    29.491870-9.761595j   20.338212+18.961825j   \n1043  24.344030+133.216239j -157.397915+94.220606j   18.373604-66.492929j   \n...                     ...                    ...                    ...   \n930     51.825282-7.122598j   33.644640-25.796774j    41.393603-8.701162j   \n46     -19.753849-1.322027j  -19.659597-17.395378j    0.894073-12.853528j   \n790    -3.383257-26.886866j  -93.887003+34.040693j  -81.888564+60.106864j   \n953    90.848273-11.180504j    93.075411+1.865543j    63.863041-7.824432j   \n1072    35.581632+4.704350j   50.571061+35.995138j  -16.054746-12.762860j   \n\n                         86                    87                    88  \\\n604  -261.403229+34.129059j -257.378401+7.666345j -252.139731-2.213865j   \n1568   21.090029-22.364289j   11.964410-2.027536j   23.433118-6.635780j   \n480     22.170692+5.386839j   14.863870-5.242623j    4.592552+4.699494j   \n108    30.940568+23.769582j  32.053833+15.927478j   22.940768+4.697138j   \n1043   -27.723875-6.837443j  75.267507+40.259580j -52.278376-95.242595j   \n...                     ...                   ...                   ...   \n930    18.237049-17.813142j   51.849250+1.342216j   37.319872-6.076890j   \n46     -5.588398-22.540657j -15.681470-13.158548j   6.190644-27.341979j   \n790   -48.287558+55.305519j  32.742069+13.978292j -86.759819-77.007765j   \n953    72.136636-20.084143j   77.668720-8.815140j  98.704081-31.788379j   \n1072    3.979175+39.488064j   45.356455-2.883872j  29.376515+12.244953j   \n\n                        89  \n604  -230.000000+0.000000j  \n1568    9.000000+0.000000j  \n480    26.000000+0.000000j  \n108    51.000000+0.000000j  \n1043  -13.000000+0.000000j  \n...                    ...  \n930    37.000000+0.000000j  \n46     21.000000+0.000000j  \n790    -3.000000+0.000000j  \n953    92.000000+0.000000j  \n1072  -21.000000+0.000000j  \n\n[1600 rows x 90 columns]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComplexWarning\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mComplexWarning\u001b[0m: Casting complex values to real discards the imaginary part",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-41b5f25551e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodelSVM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodelSVM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodelSVM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    146\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[0;32m    147\u001b[0m                          \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                          accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    737\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    740\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n\u001b[1;32m--> 518\u001b[1;33m                                  \"{}\\n\".format(array))\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;31m# It is possible that the np.array(..) gave no warning. This happens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Complex data not supported\n                         0                          1   \\\n604  -8788.000000+0.000000j  5708.328329+10134.672561j   \n1568 -9395.000000+0.000000j   2334.869603-1870.300580j   \n480  -1156.000000+0.000000j    -504.991841+635.717354j   \n108   5865.000000+0.000000j  -6696.191849+6034.735151j   \n1043 -2875.000000+0.000000j   1430.796942-1006.132391j   \n...                     ...                        ...   \n930  -4671.000000+0.000000j   1254.695202-3708.271958j   \n46     855.000000+0.000000j    678.669892+1956.327346j   \n790  -5963.000000+0.000000j   -777.201745-1412.382335j   \n953   -892.000000+0.000000j     -269.207770+79.801160j   \n1072 -5837.000000+0.000000j    1394.538256+377.835486j   \n\n                            2                         3   \\\n604    2780.998370-314.501393j    -95.232404+974.907993j   \n1568   -395.257176-264.087456j    414.587609-396.763690j   \n480     184.449789+274.084637j  -469.358628+1785.635773j   \n108   4531.612275-7520.019901j -4080.701690-2898.602235j   \n1043  1015.351945-1482.910749j   -956.714034+378.087838j   \n...                        ...                       ...   \n930   -623.302006+1391.651449j     197.895388-79.756171j   \n46       13.561687-947.363405j   102.068237+1962.630588j   \n790    1226.853222-426.193825j   282.866656+3036.304591j   \n953   1414.301915-2535.269245j   578.927892-2683.123205j   \n1072    353.443066-445.711642j  -1592.789235-358.178666j   \n\n                            4                         5   \\\n604      -7.042932+428.575440j   1254.951227+967.647334j   \n1568     12.130984-292.276493j   1025.598694+740.955580j   \n480    -693.422669-809.701889j      86.445401+23.851638j   \n108  -2738.800868+2308.000154j  1443.230794-1032.970257j   \n1043  -248.368572-1807.166688j   473.861995-2616.534473j   \n...                        ...                       ...   \n930    269.440401-1094.541730j   -744.407385+177.529815j   \n46     -203.930122+150.435210j     658.196087+74.566679j   \n790  -4232.151600-2907.095646j  2744.391406+1380.490455j   \n953       594.816322+3.889325j  -1544.372681-172.920940j   \n1072   -455.893628-106.655407j   -966.455463-515.638628j   \n\n                           6                         7   \\\n604   -488.226042+259.083355j  1686.127980+1128.533854j   \n1568  -213.630160-171.334438j     1071.887885+4.065549j   \n480    277.969932-481.030995j   1052.821576+830.274887j   \n108  -263.459838-1571.638580j  -1158.145412+423.828856j   \n1043  709.911349-1669.181974j  -1161.120710+927.196686j   \n...                       ...                       ...   \n930    372.739896-499.815997j   1232.693521+220.169388j   \n46      71.827800-446.975428j   -764.468767+731.842634j   \n790   -131.195514-239.446678j    462.439438-999.345115j   \n953  -816.578516-1002.042296j  -1159.101694+242.366210j   \n1072   622.719570+340.621540j   -162.795155-943.489233j   \n\n                           8                        9   ...  \\\n604    784.057706+832.972955j   758.464779+303.061506j  ...   \n1568    122.956167+11.879631j  -197.115015-838.351261j  ...   \n480   858.871642+1322.690163j   766.846242+662.284864j  ...   \n108    -759.383942-26.361564j  -275.597712+918.851702j  ...   \n1043   236.824491-421.034211j  -366.919321-283.223812j  ...   \n...                       ...                      ...  ...   \n930   -1228.875175+56.022216j  -384.132343-424.631991j  ...   \n46     328.136282-929.558758j  -850.672242-665.367028j  ...   \n790   -60.741766-2451.677349j  536.281270+1333.531140j  ...   \n953  -422.072584-1815.271972j  -780.778204+466.777288j  ...   \n1072   -443.244142-19.693921j   187.789151+246.762124j  ...   \n\n                         80                      81                     82  \\\n604  -307.329255+50.109211j  -271.715524+73.322641j -285.592659+67.176458j   \n1568  -28.812135-24.499594j      8.833257+4.592628j   35.002237+12.656265j   \n480      6.798574+3.718442j    -7.580777+20.445611j   20.414104+10.904294j   \n108    25.374707-39.610004j    45.850375-10.426479j   28.789228-11.162034j   \n1043   17.095521+31.561462j  120.693796+128.447383j  38.284763-125.338522j   \n...                     ...                     ...                    ...   \n930    21.589043-15.436503j    52.086822+10.899734j   56.865256-18.388537j   \n46       3.511912-5.773200j   -21.302762-32.550169j   -45.595889-9.864502j   \n790    13.104367+18.257214j   -28.838710-23.160326j  -65.457755+86.191976j   \n953     78.298689+0.394558j    53.614551-34.330913j   60.227138-16.135897j   \n1072   -15.806639+8.149046j    43.574149+16.609876j    19.162287-7.058266j   \n\n                         83                     84                     85  \\\n604  -267.696435+53.696272j -285.193465+54.175212j -262.606740+47.992359j   \n1568    29.024643-5.525798j    -5.419846+0.586436j    1.743553-13.047884j   \n480    20.364895-26.337695j    -7.459384+0.943095j    24.210562-6.141698j   \n108     5.435982+45.768741j    29.491870-9.761595j   20.338212+18.961825j   \n1043  24.344030+133.216239j -157.397915+94.220606j   18.373604-66.492929j   \n...                     ...                    ...                    ...   \n930     51.825282-7.122598j   33.644640-25.796774j    41.393603-8.701162j   \n46     -19.753849-1.322027j  -19.659597-17.395378j    0.894073-12.853528j   \n790    -3.383257-26.886866j  -93.887003+34.040693j  -81.888564+60.106864j   \n953    90.848273-11.180504j    93.075411+1.865543j    63.863041-7.824432j   \n1072    35.581632+4.704350j   50.571061+35.995138j  -16.054746-12.762860j   \n\n                         86                    87                    88  \\\n604  -261.403229+34.129059j -257.378401+7.666345j -252.139731-2.213865j   \n1568   21.090029-22.364289j   11.964410-2.027536j   23.433118-6.635780j   \n480     22.170692+5.386839j   14.863870-5.242623j    4.592552+4.699494j   \n108    30.940568+23.769582j  32.053833+15.927478j   22.940768+4.697138j   \n1043   -27.723875-6.837443j  75.267507+40.259580j -52.278376-95.242595j   \n...                     ...                   ...                   ...   \n930    18.237049-17.813142j   51.849250+1.342216j   37.319872-6.076890j   \n46     -5.588398-22.540657j -15.681470-13.158548j   6.190644-27.341979j   \n790   -48.287558+55.305519j  32.742069+13.978292j -86.759819-77.007765j   \n953    72.136636-20.084143j   77.668720-8.815140j  98.704081-31.788379j   \n1072    3.979175+39.488064j   45.356455-2.883872j  29.376515+12.244953j   \n\n                        89  \n604  -230.000000+0.000000j  \n1568    9.000000+0.000000j  \n480    26.000000+0.000000j  \n108    51.000000+0.000000j  \n1043  -13.000000+0.000000j  \n...                    ...  \n930    37.000000+0.000000j  \n46     21.000000+0.000000j  \n790    -3.000000+0.000000j  \n953    92.000000+0.000000j  \n1072  -21.000000+0.000000j  \n\n[1600 rows x 90 columns]\n"
     ]
    }
   ],
   "source": [
    "##SVM \n",
    "from sklearn import svm\n",
    "modelSVM = svm.SVC(gamma=0.001, C=100.) \n",
    "modelSVM.fit(X_train, y_train)\n",
    "print(classification_report(y_test,modelSVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Logistic regression: \n",
    "from sklearn import linear_model\n",
    "modelLR = linear_model.LogisticRegression(C=1e5, max_iter=1000)    \n",
    "modelLR.fit(X_train, y_train)\n",
    "print(classification_report(y_test, modelLR.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF=RandomForestClassifier(n_estimators=1000)   \n",
    "modelRF.fit(X_train, y_train)\n",
    "print(classification_report(y_test, modelRF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural network: \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNN = MLPClassifier(hidden_layer_sizes=(5,5,5), max_iter=500) \n",
    "#3 hidden layers with 13 neurons in each layer \n",
    "modelNN.fit(X_train, y_train)\n",
    "print(classification_report(y_test,modelNN.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using frequency domain and time domain by concatenating matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fft, X_test_fft, y_train_fft, y_test_fft = train_test_split(X_fft, y, test_size = 0.2)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_fft = sc.fit_transform(X_train_fft)\n",
    "X_test_fft = sc.transform(X_test_fft)\n",
    "\n",
    "clf_fft = XGBClassifier()\n",
    "clf_fft.fit(X_train_fft, y_train_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
