{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Warning: I reuse variable names in this notebook! \n",
    "#Just to be safe, the cells in this notebook should only be run in order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statistics import mean \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>-38</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>-94</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-59</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2   X3   X4   X5   X6   X7   X8   X9  X10  ...  X170  X171  X172  \\\n",
       "0  135  190  229  223  192  125   55   -9  -33  -38  ...   -17   -15   -31   \n",
       "1  386  382  356  331  320  315  307  272  244  232  ...   164   150   146   \n",
       "2  -32  -39  -47  -37  -32  -36  -57  -73  -85  -94  ...    57    64    48   \n",
       "3 -105 -101  -96  -92  -89  -95 -102 -100  -87  -79  ...   -82   -81   -80   \n",
       "4   -9  -65  -98 -102  -78  -48  -16    0  -21  -59  ...     4     2   -12   \n",
       "\n",
       "   X173  X174  X175  X176  X177  X178  class  \n",
       "0   -77  -103  -127  -116   -83   -51      0  \n",
       "1   152   157   156   154   143   129      1  \n",
       "2    19   -12   -30   -35   -35   -36      0  \n",
       "3   -77   -85   -77   -72   -69   -65      0  \n",
       "4   -32   -41   -65   -83   -89   -73      0  \n",
       "\n",
       "[5 rows x 179 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('processedData.csv')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3010.000000+0.000000j</td>\n",
       "      <td>2446.790792+450.260364j</td>\n",
       "      <td>-2657.829269-1481.143752j</td>\n",
       "      <td>3723.266454-2659.484308j</td>\n",
       "      <td>1650.562647-2466.994586j</td>\n",
       "      <td>918.031493-18.948320j</td>\n",
       "      <td>-202.429242+619.811519j</td>\n",
       "      <td>-294.802718-771.511120j</td>\n",
       "      <td>176.079389-1888.520570j</td>\n",
       "      <td>-504.650611-1214.910117j</td>\n",
       "      <td>...</td>\n",
       "      <td>86.688657-3.666185j</td>\n",
       "      <td>23.859198+4.143637j</td>\n",
       "      <td>4.385593-6.296764j</td>\n",
       "      <td>97.615584-33.940149j</td>\n",
       "      <td>78.878946-13.979682j</td>\n",
       "      <td>127.280997+23.319018j</td>\n",
       "      <td>96.094059-38.091402j</td>\n",
       "      <td>67.199918-16.918763j</td>\n",
       "      <td>93.600757+9.450320j</td>\n",
       "      <td>44.000000+0.000000j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5004.000000+0.000000j</td>\n",
       "      <td>1307.724581-7404.532738j</td>\n",
       "      <td>15020.767668+7130.189030j</td>\n",
       "      <td>-25344.161119+18210.881275j</td>\n",
       "      <td>21871.778701-2423.041744j</td>\n",
       "      <td>15739.921558-8177.167310j</td>\n",
       "      <td>-1253.147988+6344.224700j</td>\n",
       "      <td>12011.708894-11466.934692j</td>\n",
       "      <td>-11522.049649-12855.153754j</td>\n",
       "      <td>-6064.440312-97.089163j</td>\n",
       "      <td>...</td>\n",
       "      <td>189.384133-136.906577j</td>\n",
       "      <td>199.310800+101.951374j</td>\n",
       "      <td>-68.063866+64.827065j</td>\n",
       "      <td>146.539590-89.966144j</td>\n",
       "      <td>236.969490+0.559303j</td>\n",
       "      <td>53.858172+129.253662j</td>\n",
       "      <td>89.342091-40.571556j</td>\n",
       "      <td>238.474919-74.281084j</td>\n",
       "      <td>151.153163+134.988788j</td>\n",
       "      <td>50.000000+0.000000j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7840.000000+0.000000j</td>\n",
       "      <td>936.496752-664.893496j</td>\n",
       "      <td>440.289506+2359.520081j</td>\n",
       "      <td>-347.459321+1292.812690j</td>\n",
       "      <td>-806.898519+1090.135575j</td>\n",
       "      <td>676.089935+1077.245652j</td>\n",
       "      <td>-273.567749-826.970569j</td>\n",
       "      <td>626.621552-1154.763492j</td>\n",
       "      <td>877.326201+1371.650362j</td>\n",
       "      <td>85.266287+1377.544734j</td>\n",
       "      <td>...</td>\n",
       "      <td>36.526101+6.499210j</td>\n",
       "      <td>-39.752692-13.378318j</td>\n",
       "      <td>25.801254-1.111489j</td>\n",
       "      <td>-14.804403+7.094747j</td>\n",
       "      <td>13.459686-29.988141j</td>\n",
       "      <td>-0.581226-14.920744j</td>\n",
       "      <td>-2.955536+24.453640j</td>\n",
       "      <td>-3.838489+1.794738j</td>\n",
       "      <td>-9.148489-9.209289j</td>\n",
       "      <td>-28.000000+0.000000j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-12266.000000+0.000000j</td>\n",
       "      <td>-654.541662+10.781029j</td>\n",
       "      <td>85.298621+611.952118j</td>\n",
       "      <td>-519.449332-90.799334j</td>\n",
       "      <td>-407.503142+250.124809j</td>\n",
       "      <td>60.813056-145.825609j</td>\n",
       "      <td>-163.169987-66.759576j</td>\n",
       "      <td>-600.328983+190.555823j</td>\n",
       "      <td>53.897860-81.703121j</td>\n",
       "      <td>409.127836+108.072400j</td>\n",
       "      <td>...</td>\n",
       "      <td>20.808978+42.740584j</td>\n",
       "      <td>-26.813882-6.401015j</td>\n",
       "      <td>-15.043018-18.847958j</td>\n",
       "      <td>-24.863560-5.160417j</td>\n",
       "      <td>-3.014438-27.562262j</td>\n",
       "      <td>-9.672253+8.434902j</td>\n",
       "      <td>-10.750488+18.520684j</td>\n",
       "      <td>-7.911091+2.967247j</td>\n",
       "      <td>-33.001732+13.067275j</td>\n",
       "      <td>-22.000000+0.000000j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1184.000000+0.000000j</td>\n",
       "      <td>-1599.385327+2043.789895j</td>\n",
       "      <td>-685.634998+245.900831j</td>\n",
       "      <td>-892.832855+710.693729j</td>\n",
       "      <td>-699.408701-209.596507j</td>\n",
       "      <td>-487.089669+895.536939j</td>\n",
       "      <td>-254.288330+417.071151j</td>\n",
       "      <td>-198.876374-459.240454j</td>\n",
       "      <td>244.165460+571.911329j</td>\n",
       "      <td>-589.041889-749.126341j</td>\n",
       "      <td>...</td>\n",
       "      <td>36.145361+26.748787j</td>\n",
       "      <td>11.816407+31.999144j</td>\n",
       "      <td>12.645645+22.149077j</td>\n",
       "      <td>33.058688+13.953826j</td>\n",
       "      <td>50.649279-49.306473j</td>\n",
       "      <td>52.758400+8.622748j</td>\n",
       "      <td>48.225392-27.058742j</td>\n",
       "      <td>41.106474-11.590343j</td>\n",
       "      <td>19.383760+30.722072j</td>\n",
       "      <td>62.000000+0.000000j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                         1   \\\n",
       "0  -3010.000000+0.000000j   2446.790792+450.260364j   \n",
       "1   5004.000000+0.000000j  1307.724581-7404.532738j   \n",
       "2  -7840.000000+0.000000j    936.496752-664.893496j   \n",
       "3 -12266.000000+0.000000j    -654.541662+10.781029j   \n",
       "4  -1184.000000+0.000000j -1599.385327+2043.789895j   \n",
       "\n",
       "                          2                           3   \\\n",
       "0  -2657.829269-1481.143752j    3723.266454-2659.484308j   \n",
       "1  15020.767668+7130.189030j -25344.161119+18210.881275j   \n",
       "2    440.289506+2359.520081j    -347.459321+1292.812690j   \n",
       "3      85.298621+611.952118j      -519.449332-90.799334j   \n",
       "4    -685.634998+245.900831j     -892.832855+710.693729j   \n",
       "\n",
       "                          4                          5   \\\n",
       "0   1650.562647-2466.994586j      918.031493-18.948320j   \n",
       "1  21871.778701-2423.041744j  15739.921558-8177.167310j   \n",
       "2   -806.898519+1090.135575j    676.089935+1077.245652j   \n",
       "3    -407.503142+250.124809j      60.813056-145.825609j   \n",
       "4    -699.408701-209.596507j    -487.089669+895.536939j   \n",
       "\n",
       "                         6                           7   \\\n",
       "0   -202.429242+619.811519j     -294.802718-771.511120j   \n",
       "1 -1253.147988+6344.224700j  12011.708894-11466.934692j   \n",
       "2   -273.567749-826.970569j     626.621552-1154.763492j   \n",
       "3    -163.169987-66.759576j     -600.328983+190.555823j   \n",
       "4   -254.288330+417.071151j     -198.876374-459.240454j   \n",
       "\n",
       "                           8                        9   ...  \\\n",
       "0     176.079389-1888.520570j -504.650611-1214.910117j  ...   \n",
       "1 -11522.049649-12855.153754j  -6064.440312-97.089163j  ...   \n",
       "2     877.326201+1371.650362j   85.266287+1377.544734j  ...   \n",
       "3        53.897860-81.703121j   409.127836+108.072400j  ...   \n",
       "4      244.165460+571.911329j  -589.041889-749.126341j  ...   \n",
       "\n",
       "                       80                      81                    82  \\\n",
       "0     86.688657-3.666185j     23.859198+4.143637j    4.385593-6.296764j   \n",
       "1  189.384133-136.906577j  199.310800+101.951374j -68.063866+64.827065j   \n",
       "2     36.526101+6.499210j   -39.752692-13.378318j   25.801254-1.111489j   \n",
       "3    20.808978+42.740584j    -26.813882-6.401015j -15.043018-18.847958j   \n",
       "4    36.145361+26.748787j    11.816407+31.999144j  12.645645+22.149077j   \n",
       "\n",
       "                      83                    84                     85  \\\n",
       "0   97.615584-33.940149j  78.878946-13.979682j  127.280997+23.319018j   \n",
       "1  146.539590-89.966144j  236.969490+0.559303j  53.858172+129.253662j   \n",
       "2   -14.804403+7.094747j  13.459686-29.988141j   -0.581226-14.920744j   \n",
       "3   -24.863560-5.160417j  -3.014438-27.562262j    -9.672253+8.434902j   \n",
       "4   33.058688+13.953826j  50.649279-49.306473j    52.758400+8.622748j   \n",
       "\n",
       "                     86                     87                      88  \\\n",
       "0  96.094059-38.091402j   67.199918-16.918763j     93.600757+9.450320j   \n",
       "1  89.342091-40.571556j  238.474919-74.281084j  151.153163+134.988788j   \n",
       "2  -2.955536+24.453640j    -3.838489+1.794738j     -9.148489-9.209289j   \n",
       "3 -10.750488+18.520684j    -7.911091+2.967247j   -33.001732+13.067275j   \n",
       "4  48.225392-27.058742j   41.106474-11.590343j    19.383760+30.722072j   \n",
       "\n",
       "                    89  \n",
       "0  44.000000+0.000000j  \n",
       "1  50.000000+0.000000j  \n",
       "2 -28.000000+0.000000j  \n",
       "3 -22.000000+0.000000j  \n",
       "4  62.000000+0.000000j  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see: https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.rfft.html for difference\n",
    "#between rfft and regular fft. We should briefly mention the difference on our slides\n",
    "#Note that j is used instead of i for complex numbers\n",
    "\n",
    "X = pd.DataFrame(np.fft.rfft(d.iloc[:,0:178]))   #indexing includes entire data matrix except label column\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.absolute(X)  \n",
    "#sklearn can't work with complex numbers. I take the magnitude of the complex\n",
    "#numbers - we just lose phase information this way, but that's not too important\n",
    "#to begin with (I think. But I could be wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3010.0</td>\n",
       "      <td>2487.874510</td>\n",
       "      <td>3042.670412</td>\n",
       "      <td>4575.540392</td>\n",
       "      <td>2968.235055</td>\n",
       "      <td>918.227021</td>\n",
       "      <td>652.030611</td>\n",
       "      <td>825.916491</td>\n",
       "      <td>1896.711337</td>\n",
       "      <td>1315.552672</td>\n",
       "      <td>...</td>\n",
       "      <td>86.766146</td>\n",
       "      <td>24.216338</td>\n",
       "      <td>7.673504</td>\n",
       "      <td>103.347646</td>\n",
       "      <td>80.108175</td>\n",
       "      <td>129.399493</td>\n",
       "      <td>103.368386</td>\n",
       "      <td>69.296995</td>\n",
       "      <td>94.076619</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5004.0</td>\n",
       "      <td>7519.125524</td>\n",
       "      <td>16627.178261</td>\n",
       "      <td>31208.375473</td>\n",
       "      <td>22005.586446</td>\n",
       "      <td>17737.282651</td>\n",
       "      <td>6466.805002</td>\n",
       "      <td>16606.376540</td>\n",
       "      <td>17263.041626</td>\n",
       "      <td>6065.217440</td>\n",
       "      <td>...</td>\n",
       "      <td>233.687314</td>\n",
       "      <td>223.872459</td>\n",
       "      <td>93.995948</td>\n",
       "      <td>171.952780</td>\n",
       "      <td>236.970150</td>\n",
       "      <td>140.025754</td>\n",
       "      <td>98.122680</td>\n",
       "      <td>249.775832</td>\n",
       "      <td>202.655500</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7840.0</td>\n",
       "      <td>1148.524936</td>\n",
       "      <td>2400.247875</td>\n",
       "      <td>1338.690640</td>\n",
       "      <td>1356.274600</td>\n",
       "      <td>1271.831669</td>\n",
       "      <td>871.045139</td>\n",
       "      <td>1313.823920</td>\n",
       "      <td>1628.227864</td>\n",
       "      <td>1380.181087</td>\n",
       "      <td>...</td>\n",
       "      <td>37.099808</td>\n",
       "      <td>41.943485</td>\n",
       "      <td>25.825184</td>\n",
       "      <td>16.416632</td>\n",
       "      <td>32.870226</td>\n",
       "      <td>14.932060</td>\n",
       "      <td>24.631600</td>\n",
       "      <td>4.237344</td>\n",
       "      <td>12.980980</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12266.0</td>\n",
       "      <td>654.630444</td>\n",
       "      <td>617.868310</td>\n",
       "      <td>527.325447</td>\n",
       "      <td>478.143526</td>\n",
       "      <td>157.997898</td>\n",
       "      <td>176.298853</td>\n",
       "      <td>629.846337</td>\n",
       "      <td>97.879412</td>\n",
       "      <td>423.160998</td>\n",
       "      <td>...</td>\n",
       "      <td>47.537050</td>\n",
       "      <td>27.567322</td>\n",
       "      <td>24.115097</td>\n",
       "      <td>25.393435</td>\n",
       "      <td>27.726614</td>\n",
       "      <td>12.833552</td>\n",
       "      <td>21.414685</td>\n",
       "      <td>8.449255</td>\n",
       "      <td>35.494619</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1184.0</td>\n",
       "      <td>2595.209155</td>\n",
       "      <td>728.397261</td>\n",
       "      <td>1141.155591</td>\n",
       "      <td>730.139183</td>\n",
       "      <td>1019.432565</td>\n",
       "      <td>488.478147</td>\n",
       "      <td>500.453402</td>\n",
       "      <td>621.851542</td>\n",
       "      <td>952.974618</td>\n",
       "      <td>...</td>\n",
       "      <td>44.966484</td>\n",
       "      <td>34.111182</td>\n",
       "      <td>25.504783</td>\n",
       "      <td>35.882950</td>\n",
       "      <td>70.685768</td>\n",
       "      <td>53.458401</td>\n",
       "      <td>55.297956</td>\n",
       "      <td>42.709229</td>\n",
       "      <td>36.325967</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0            1             2             3             4   \\\n",
       "0   3010.0  2487.874510   3042.670412   4575.540392   2968.235055   \n",
       "1   5004.0  7519.125524  16627.178261  31208.375473  22005.586446   \n",
       "2   7840.0  1148.524936   2400.247875   1338.690640   1356.274600   \n",
       "3  12266.0   654.630444    617.868310    527.325447    478.143526   \n",
       "4   1184.0  2595.209155    728.397261   1141.155591    730.139183   \n",
       "\n",
       "             5            6             7             8            9   ...  \\\n",
       "0    918.227021   652.030611    825.916491   1896.711337  1315.552672  ...   \n",
       "1  17737.282651  6466.805002  16606.376540  17263.041626  6065.217440  ...   \n",
       "2   1271.831669   871.045139   1313.823920   1628.227864  1380.181087  ...   \n",
       "3    157.997898   176.298853    629.846337     97.879412   423.160998  ...   \n",
       "4   1019.432565   488.478147    500.453402    621.851542   952.974618  ...   \n",
       "\n",
       "           80          81         82          83          84          85  \\\n",
       "0   86.766146   24.216338   7.673504  103.347646   80.108175  129.399493   \n",
       "1  233.687314  223.872459  93.995948  171.952780  236.970150  140.025754   \n",
       "2   37.099808   41.943485  25.825184   16.416632   32.870226   14.932060   \n",
       "3   47.537050   27.567322  24.115097   25.393435   27.726614   12.833552   \n",
       "4   44.966484   34.111182  25.504783   35.882950   70.685768   53.458401   \n",
       "\n",
       "           86          87          88    89  \n",
       "0  103.368386   69.296995   94.076619  44.0  \n",
       "1   98.122680  249.775832  202.655500  50.0  \n",
       "2   24.631600    4.237344   12.980980  28.0  \n",
       "3   21.414685    8.449255   35.494619  22.0  \n",
       "4   55.297956   42.709229   36.325967  62.0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "11495    0\n",
       "11496    1\n",
       "11497    0\n",
       "11498    0\n",
       "11499    0\n",
       "Name: class, Length: 11500, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = d.iloc[:,178]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate original time domain data to frequency domain data to use \n",
    "#them in prediction simulataneously \n",
    "bigX = d.iloc[:,0:178].join(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>-38</td>\n",
       "      <td>...</td>\n",
       "      <td>86.766146</td>\n",
       "      <td>24.216338</td>\n",
       "      <td>7.673504</td>\n",
       "      <td>103.347646</td>\n",
       "      <td>80.108175</td>\n",
       "      <td>129.399493</td>\n",
       "      <td>103.368386</td>\n",
       "      <td>69.296995</td>\n",
       "      <td>94.076619</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>233.687314</td>\n",
       "      <td>223.872459</td>\n",
       "      <td>93.995948</td>\n",
       "      <td>171.952780</td>\n",
       "      <td>236.970150</td>\n",
       "      <td>140.025754</td>\n",
       "      <td>98.122680</td>\n",
       "      <td>249.775832</td>\n",
       "      <td>202.655500</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>-94</td>\n",
       "      <td>...</td>\n",
       "      <td>37.099808</td>\n",
       "      <td>41.943485</td>\n",
       "      <td>25.825184</td>\n",
       "      <td>16.416632</td>\n",
       "      <td>32.870226</td>\n",
       "      <td>14.932060</td>\n",
       "      <td>24.631600</td>\n",
       "      <td>4.237344</td>\n",
       "      <td>12.980980</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>47.537050</td>\n",
       "      <td>27.567322</td>\n",
       "      <td>24.115097</td>\n",
       "      <td>25.393435</td>\n",
       "      <td>27.726614</td>\n",
       "      <td>12.833552</td>\n",
       "      <td>21.414685</td>\n",
       "      <td>8.449255</td>\n",
       "      <td>35.494619</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-59</td>\n",
       "      <td>...</td>\n",
       "      <td>44.966484</td>\n",
       "      <td>34.111182</td>\n",
       "      <td>25.504783</td>\n",
       "      <td>35.882950</td>\n",
       "      <td>70.685768</td>\n",
       "      <td>53.458401</td>\n",
       "      <td>55.297956</td>\n",
       "      <td>42.709229</td>\n",
       "      <td>36.325967</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2   X3   X4   X5   X6   X7   X8   X9  X10  ...          80  \\\n",
       "0  135  190  229  223  192  125   55   -9  -33  -38  ...   86.766146   \n",
       "1  386  382  356  331  320  315  307  272  244  232  ...  233.687314   \n",
       "2  -32  -39  -47  -37  -32  -36  -57  -73  -85  -94  ...   37.099808   \n",
       "3 -105 -101  -96  -92  -89  -95 -102 -100  -87  -79  ...   47.537050   \n",
       "4   -9  -65  -98 -102  -78  -48  -16    0  -21  -59  ...   44.966484   \n",
       "\n",
       "           81         82          83          84          85          86  \\\n",
       "0   24.216338   7.673504  103.347646   80.108175  129.399493  103.368386   \n",
       "1  223.872459  93.995948  171.952780  236.970150  140.025754   98.122680   \n",
       "2   41.943485  25.825184   16.416632   32.870226   14.932060   24.631600   \n",
       "3   27.567322  24.115097   25.393435   27.726614   12.833552   21.414685   \n",
       "4   34.111182  25.504783   35.882950   70.685768   53.458401   55.297956   \n",
       "\n",
       "           87          88    89  \n",
       "0   69.296995   94.076619  44.0  \n",
       "1  249.775832  202.655500  50.0  \n",
       "2    4.237344   12.980980  28.0  \n",
       "3    8.449255   35.494619  22.0  \n",
       "4   42.709229   36.325967  62.0  \n",
       "\n",
       "[5 rows x 268 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11500, 179)\n",
      "(11500, 90)\n",
      "(11500,)\n",
      "(11500, 268)\n"
     ]
    }
   ],
   "source": [
    "print(d.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(bigX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using only frequency domain: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9200, 90)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm that only rfft features are being used: there should be 90 columns: \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      1835\n",
      "           1       0.00      0.00      0.00       465\n",
      "\n",
      "    accuracy                           0.80      2300\n",
      "   macro avg       0.40      0.50      0.44      2300\n",
      "weighted avg       0.64      0.80      0.71      2300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "##SVM \n",
    "from sklearn import svm\n",
    "modelSVM = svm.SVC(gamma=0.001, C=100.) \n",
    "modelSVM.fit(X_train, y_train)\n",
    "print(classification_report(y_test,modelSVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1835\n",
      "           1       0.87      0.90      0.89       465\n",
      "\n",
      "    accuracy                           0.95      2300\n",
      "   macro avg       0.92      0.93      0.93      2300\n",
      "weighted avg       0.95      0.95      0.95      2300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "##Logistic regression: \n",
    "from sklearn import linear_model\n",
    "modelLR = linear_model.LogisticRegression(C=1e5, max_iter=1000)    \n",
    "modelLR.fit(X_train, y_train)\n",
    "print(classification_report(y_test, modelLR.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1835\n",
      "           1       0.95      0.96      0.96       465\n",
      "\n",
      "    accuracy                           0.98      2300\n",
      "   macro avg       0.97      0.98      0.97      2300\n",
      "weighted avg       0.98      0.98      0.98      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Random forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF=RandomForestClassifier(n_estimators=1000)   \n",
    "modelRF.fit(X_train, y_train)\n",
    "print(classification_report(y_test, modelRF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural network: \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1835\n",
      "           1       0.94      0.95      0.94       465\n",
      "\n",
      "    accuracy                           0.98      2300\n",
      "   macro avg       0.96      0.97      0.97      2300\n",
      "weighted avg       0.98      0.98      0.98      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelNN = MLPClassifier(hidden_layer_sizes=(5,5,5), max_iter=500) \n",
    "#3 hidden layers with 13 neurons in each layer \n",
    "modelNN.fit(X_train, y_train)\n",
    "print(classification_report(y_test,modelNN.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      "SVM_cv_results: 0.8000000045364676\n",
      "LR_cv_results: 0.9539133678948654\n",
      "NeuralNet_cv_results: 0.8507747356679719\n",
      "RandomForest_cv_results: 0.9801740715200428\n",
      "\n",
      "Training times:\n",
      "SVM_cv_results: 41.227339585622154\n",
      "LR_cv_results: 2.6803446610768638\n",
      "NeuralNet_cv_results: 4.346126635869344\n",
      "RandomForest_cv_results: 84.04317617416382\n",
      "\n",
      "Prediction times:\n",
      "SVM_cv_results: 5.913506110509236\n",
      "LR_cv_results: 0.0\n",
      "NeuralNet_cv_results: 0.006034374237060547\n",
      "RandomForest_cv_results: 0.6274352073669434\n"
     ]
    }
   ],
   "source": [
    "from CVreportingFramework import hugeFramework\n",
    "hugeFramework(modelSVM, modelLR, modelNN, modelRF, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using frequency domain and time domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bigX, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9200, 268)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm that I'm using both sets of features: there should be 268 columns \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      1835\n",
      "           1       0.00      0.00      0.00       465\n",
      "\n",
      "    accuracy                           0.80      2300\n",
      "   macro avg       0.40      0.50      0.44      2300\n",
      "weighted avg       0.64      0.80      0.71      2300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "##SVM \n",
    "from sklearn import svm\n",
    "modelSVM = svm.SVC(gamma=0.001, C=100.) \n",
    "modelSVM.fit(X_train, y_train)\n",
    "print(classification_report(y_test,modelSVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1835\n",
      "           1       0.88      0.88      0.88       465\n",
      "\n",
      "    accuracy                           0.95      2300\n",
      "   macro avg       0.93      0.92      0.92      2300\n",
      "weighted avg       0.95      0.95      0.95      2300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "##Logistic regression: \n",
    "from sklearn import linear_model\n",
    "modelLR = linear_model.LogisticRegression(C=1e5, max_iter=1000)    \n",
    "modelLR.fit(X_train, y_train)\n",
    "print(classification_report(y_test, modelLR.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1835\n",
      "           1       0.95      0.94      0.94       465\n",
      "\n",
      "    accuracy                           0.98      2300\n",
      "   macro avg       0.97      0.96      0.97      2300\n",
      "weighted avg       0.98      0.98      0.98      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Random forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRF=RandomForestClassifier(n_estimators=1000)   \n",
    "modelRF.fit(X_train, y_train)\n",
    "print(classification_report(y_test, modelRF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Neural network: \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1835\n",
      "           1       0.96      0.90      0.93       465\n",
      "\n",
      "    accuracy                           0.97      2300\n",
      "   macro avg       0.97      0.95      0.96      2300\n",
      "weighted avg       0.97      0.97      0.97      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelNN = MLPClassifier(hidden_layer_sizes=(5,5,5), max_iter=500) \n",
    "#3 hidden layers with 13 neurons in each layer \n",
    "modelNN.fit(X_train, y_train)\n",
    "print(classification_report(y_test,modelNN.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      "SVM_cv_results: 0.8000000045364676\n",
      "LR_cv_results: 0.9539133678948654\n",
      "NeuralNet_cv_results: 0.8647008519440782\n",
      "RandomForest_cv_results: 0.9799131792685427\n",
      "\n",
      "Training times:\n",
      "SVM_cv_results: 47.3724168141683\n",
      "LR_cv_results: 2.7789488633473716\n",
      "NeuralNet_cv_results: 6.87134329477946\n",
      "RandomForest_cv_results: 90.61205204327901\n",
      "\n",
      "Prediction times:\n",
      "SVM_cv_results: 6.338093439737956\n",
      "LR_cv_results: 0.0033235549926757812\n",
      "NeuralNet_cv_results: 0.008371829986572266\n",
      "RandomForest_cv_results: 0.7555335362752279\n"
     ]
    }
   ],
   "source": [
    "hugeFramework(modelSVM, modelLR, modelNN, modelRF, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
